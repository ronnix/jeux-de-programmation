{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash minimal discriminant\n",
    "\n",
    "Votre système de gestion de sources est en panne et il est devenu impossible de définir des tags.\n",
    "Vous allez devoir noter dans votre cahier l'identifiant des révisions que vous avez livré ou que vous allez livrer.\n",
    "\n",
    "Comme copier un SHA-1 intégralement est long et soumis à erreur, vous écrivez un script pour obtenir le plus petit SHA-1 discriminant par commit pour un dépot donné.\n",
    "\n",
    "Vous avez en entrée la liste de tous les commits avec leur hash :\n",
    "\n",
    "```\n",
    "message,hash\n",
    "foo,d5acd0e29ec0785872bdb17cb07d75d00adc3d2f\n",
    "bar,417b5f004f35946d9cdc4df18681d962f2b86295\n",
    "baz,417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c\n",
    "qux,d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa\n",
    "```\n",
    "\n",
    "En sortie, le message avec le plus petit préfixe qui permet d'identifier ce commit :\n",
    "\n",
    "```\n",
    "message,short_hash,hash\n",
    "foo,d5acd,d5acd0e29ec0785872bdb17cb07d75d00adc3d2f\n",
    "bar,417b5f00,417b5f004f35946d9cdc4df18681d962f2b86295\n",
    "baz,417b5f09,417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c\n",
    "qux,d5ac7,d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa\n",
    "```\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par une fonction qui peut lire les données d'entrée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def parse_input(text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Construit un dictionnaire: hash -> message de commit\n",
    "    \"\"\"\n",
    "    return {row[\"hash\"]: row[\"message\"] for row in csv.DictReader(text.splitlines())}\n",
    "\n",
    "\n",
    "sample_data = \"\"\"message,hash\n",
    "foo,d5acd0e29ec0785872bdb17cb07d75d00adc3d2f\n",
    "bar,417b5f004f35946d9cdc4df18681d962f2b86295\n",
    "baz,417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c\n",
    "qux,d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "commits = parse_input(sample_data)\n",
    "\n",
    "\n",
    "assert commits == {\n",
    "    \"d5acd0e29ec0785872bdb17cb07d75d00adc3d2f\": \"foo\",\n",
    "    \"417b5f004f35946d9cdc4df18681d962f2b86295\": \"bar\",\n",
    "    \"417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c\": \"baz\",\n",
    "    \"d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa\": \"qux\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On aura aussi besoin d'une fonction qui calcule le préfixe commun de deux chaînes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import takewhile\n",
    "\n",
    "\n",
    "def common_prefix(s1: str, s2: str) -> str:\n",
    "    # On itère en parallèle sur les deux chaînes avec zip(),\n",
    "    # qui nous renvoie une paire de caractères,\n",
    "    # et on continue tant que les deux sont identiques\n",
    "    return \"\".join(\n",
    "        pair[0] for pair in takewhile(lambda pair: pair[0] == pair[1], zip(s1, s2))\n",
    "    )\n",
    "\n",
    "\n",
    "assert common_prefix(\"417b5f004f35946d9cdc4df\", \"417b5f09e3f48f8f38cb33a\") == \"417b5f0\"\n",
    "assert common_prefix(\"417b5f004f35946d9cdc4df\", \"d5acd0e29ec0785872bdb17\") == \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On écrit maintenant la fonction qui, à partir d'une liste de hashes, va déterminer pour chacun le préfixe discriminant minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "def minimal_prefixes(hashes: Iterable[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Construit un dictionnaire qui associe un préfixe minimal à chaque hash\n",
    "    \"\"\"\n",
    "    prefixes: Dict[str, str] = {}\n",
    "    for hash_ in hashes:\n",
    "        add_hash(hash_, prefixes)\n",
    "    return prefixes\n",
    "\n",
    "\n",
    "def add_hash(this_hash: str, prefixes: Dict[str, str]) -> None:\n",
    "    \"\"\"\n",
    "    Insère un nouveau hash dans le dictionnaire\n",
    "    \n",
    "    Si le hash commence par le même préfixe qu'un autre déjà dans le\n",
    "    dictionnaire, celui-ci n'est plus discriminant.\n",
    "    \n",
    "    Le nouveau préfixe minimal de chacun des deux hash sera le préfixe\n",
    "    commun concaténé au caractère suivant.\n",
    "    \"\"\"\n",
    "    for other_hash, prefix in prefixes.items():\n",
    "        if this_hash.startswith(prefix):\n",
    "            common = common_prefix(this_hash, other_hash)\n",
    "            prefixes[this_hash] = common + this_hash[len(common)]\n",
    "            prefixes[other_hash] = common + other_hash[len(common)]\n",
    "            return\n",
    "    prefixes[this_hash] = this_hash[0]\n",
    "    \n",
    "\n",
    "hashes = commits.keys()\n",
    "\n",
    "\n",
    "prefixes = minimal_prefixes(hashes)\n",
    "\n",
    "\n",
    "assert prefixes == {\n",
    "    \"d5acd0e29ec0785872bdb17cb07d75d00adc3d2f\": \"d5acd\",\n",
    "    \"417b5f004f35946d9cdc4df18681d962f2b86295\": \"417b5f00\",\n",
    "    \"417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c\": \"417b5f09\",\n",
    "    \"d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa\": \"d5ac7\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant si on met tout ensemble :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(commits: Dict[str, str], prefixes: Dict[str, str]) -> str:\n",
    "    lines = [\"message,short_hash,hash\"]\n",
    "    for hash_, message in commits.items():\n",
    "        lines.append(f\"{hash_},{prefixes[hash_]},{message}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "assert (\n",
    "    output(commits, prefixes)\n",
    "    == \"\"\"message,short_hash,hash\n",
    "d5acd0e29ec0785872bdb17cb07d75d00adc3d2f,d5acd,foo\n",
    "417b5f004f35946d9cdc4df18681d962f2b86295,417b5f00,bar\n",
    "417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c,417b5f09,baz\n",
    "d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa,d5ac7,qux\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message,short_hash,hash\n",
      "d5acd0e29ec0785872bdb17cb07d75d00adc3d2f,d5acd,foo\n",
      "417b5f004f35946d9cdc4df18681d962f2b86295,417b5f00,bar\n",
      "417b5f09e3f48f8f38cb33a8b7ad7ce51a47c72c,417b5f09,baz\n",
      "d5ac7b961e85aa0ba8913e0ff008cdf2ea6ebbaa,d5ac7,qux\n"
     ]
    }
   ],
   "source": [
    "def main(text: str) -> str:\n",
    "    commits = parse_input(text)\n",
    "    prefixes = minimal_prefixes(commits.keys())\n",
    "    print(output(commits, prefixes))\n",
    "\n",
    "\n",
    "main(sample_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
